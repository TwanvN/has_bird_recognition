{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a92ee37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "import pandas as pd\n",
    "import librosa\n",
    "#import librosa.display\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import normalize\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "import asyncio\n",
    "import functools\n",
    "import concurrent.futures\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "#settings\n",
    "# physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "# tf.config.set_logical_device_configuration(physical_devices[0],[tf.config.LogicalDeviceConfiguration(memory_limit=3900)])\n",
    "# tf.config.set_visible_devices(physical_devices[1:], 'GPU')\n",
    "import cmsisdsp as dsp\n",
    "import cmsisdsp.mfcc as mfcc\n",
    "from cmsisdsp.datatype import F32\n",
    "import scipy.signal as sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2573d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/birdo/MachineLearning/Data/bird_sounds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15be6935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mffc init\n",
    "mfccf32=dsp.arm_mfcc_instance_f32()\n",
    "sample_rate = 16000\n",
    "sample_time = 10\n",
    "sample_count = sample_rate * sample_time\n",
    "FFTSize = 512\n",
    "Hopsamp = int(FFTSize / 2)\n",
    "numOfDctOutputs = 32\n",
    "freq_min = 64\n",
    "freq_high = sample_rate / 2\n",
    "numOfMelFilters = 48\n",
    "row_size = int((sample_count - FFTSize) / Hopsamp)\n",
    "print(row_size)\n",
    "\n",
    "window = sig.hamming(FFTSize, sym=False)\n",
    "filtLen,filtPos,packedFilters = mfcc.melFilterMatrix(F32,freq_min, freq_high, numOfMelFilters,sample_rate,FFTSize)\n",
    "dctMatrixFilters = mfcc.dctMatrix(F32,numOfDctOutputs, numOfMelFilters)\n",
    "status=dsp.arm_mfcc_init_f32(mfccf32,FFTSize,numOfMelFilters,numOfDctOutputs,dctMatrixFilters,filtPos,filtLen,packedFilters,window)\n",
    "print(status)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aadd159",
   "metadata": {},
   "outputs": [],
   "source": [
    "species_ids = df.species_id.unique()\n",
    "species_dict = dict(zip(species_ids, range(len(species_ids))))\n",
    "tempcopy = df.copy()\n",
    "df[\"species_index\"] = df[\"species_id\"]\n",
    "tempcopy = tempcopy.applymap(lambda s: species_dict.get(s) if s in species_dict else s)#.convert_objects(\"int64\")\n",
    "df[\"species_index\"] = tempcopy[\"species_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd5a3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"file_path\"] = df[\"species_id\"]+ \"/\" + df[\"recording_id\"]   \n",
    "basePath = \"/home/birdo/MachineLearning/Data/\"\n",
    "sound_filePath = \"/home/birdo/MachineLearning/clean-audio/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc3b797",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1d03cf17",
   "metadata": {},
   "source": [
    "## Feature generating functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14139d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(array, xx, yy):\n",
    "    \"\"\"\n",
    "    :param array: numpy array\n",
    "    :param xx: desired height\n",
    "    :param yy: desirex width\n",
    "    :return: padded array\n",
    "    \"\"\"\n",
    "    h = array.shape[0]\n",
    "    w = array.shape[1]\n",
    "    a = max((xx - h) // 2,0)\n",
    "    aa = max(0,xx - a - h)\n",
    "    b = max(0,(yy - w) // 2)\n",
    "    bb = max(yy - b - w,0)\n",
    "    return np.pad(array, pad_width=((a, aa), (b, bb)), mode='constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba34227",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def generate_features(y_cut, sr):\n",
    "    tmp=np.zeros(FFTSize + 2)\n",
    "    sample_count = len(y_cut)\n",
    "    row_count = (sample_count - FFTSize) / Hopsamp\n",
    "    col_count = numOfDctOutputs\n",
    "    MFCCs = np.zeros((row_size, col_count))\n",
    "    \n",
    "\n",
    "    for i in range(0, int(row_count)):\n",
    "        start_index = i * Hopsamp\n",
    "        input = y_cut[start_index:start_index + FFTSize]\n",
    "        output = dsp.arm_mfcc_f32(mfccf32,input,tmp)\n",
    "        MFCCs[i, :] = output[0:col_count]\n",
    "\n",
    "    # MFCC_padded = padding(MFCCs, 310, 32)\n",
    "    # print(MFCC_padded.shape)\n",
    "    # print(MFCCs.shape)\n",
    "    # print(MFCCs)\n",
    "    # print(MFCCs.shape)\n",
    "\n",
    "    return MFCCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6750cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca18e607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeLabel(_labelPath,label):\n",
    "    f = open(_labelPath, \"w\")\n",
    "    f.write(str(label))\n",
    "    f.close()\n",
    "\n",
    "def saveImage(_imgPath,data):\n",
    "    data.tofile(_imgPath)\n",
    "\n",
    "async def gen_feature_from_name_id(_trainfolder,_filename,_specie_name,_recording_id,_i,executor=None):\n",
    "    # write label file\n",
    "    labelPath = basePath + str(\"/Labels/\") + _trainfolder + _specie_name + str(\"-\") + _recording_id\n",
    "    # check if file exists\n",
    "    imgPath = basePath + str(\"/Images-512/\") + _trainfolder + _specie_name + str(\"-\") + _recording_id\n",
    "\n",
    "\n",
    "    # replace .wav with .npy\n",
    "    imgPath = imgPath.replace(\".wav\", \".npy\")\n",
    "    labelPath = labelPath.replace(\".wav\", \".npy\")\n",
    "\n",
    "\n",
    "    # check if files dont contain the word .nfs\n",
    "    if \".nfs\" in imgPath or \".nfs\" in labelPath:\n",
    "        return\n",
    "    \n",
    "    loop = asyncio.get_event_loop()\n",
    "\n",
    "    # check if label exists\n",
    "    if not os.path.isfile(labelPath):\n",
    "        #write label file\n",
    "        await loop.run_in_executor(executor,functools.partial(writeLabel,labelPath,_i))\n",
    "\n",
    "    # check if image exists\n",
    "    if os.path.isfile(imgPath):\n",
    "        return\n",
    "\n",
    "    #Load the file\n",
    "    y, sr = await loop.run_in_executor(executor,functools.partial(librosa.load,_filename,sr=None))\n",
    "    #cut the file to signal start and end  \n",
    "    y_cut=y \n",
    "    #generate features & output numpy array          \n",
    "    data = await loop.run_in_executor(executor,functools.partial(generate_features,y_cut, sr))\n",
    "    # print type of numpy array\n",
    "    # print(data.dtype)\n",
    "    # print shape of numpy array\n",
    "    # print(data.shape)\n",
    "    \n",
    "    #save the numpy array\n",
    "    await loop.run_in_executor(executor,functools.partial(saveImage,imgPath, data))\n",
    "\n",
    "async def get_features(df_in, trainfolder,executor=None):   \n",
    "    features=[]     \n",
    "    labels = [] #empty array to store labels  \n",
    "    output=[]\n",
    "    #For each species, determine how many augmentations are needed\n",
    "    df_in=df_in.reset_index()     \n",
    "    for i in df_in.species_index.unique():\n",
    "        print('species:',i)    \n",
    "        #all the file indices with the same species_id     \n",
    "        filelist = df_in.loc[df_in.species_index == i].index\n",
    "        filelist_coroutines = []\n",
    "        for j in range(0,len(filelist)):   \n",
    "            try:\n",
    "                filename = str(sound_filePath) + df_in.iloc[filelist[j]].file_path #.file_path.values[j] #get the file name \n",
    "                #define the beginning time of the signal\n",
    "                specie_name = df_in.iloc[filelist[j]].species_id\n",
    "                recording_id = df_in.iloc[filelist[j]].recording_id\n",
    "\n",
    "                filelist_coroutines.append(gen_feature_from_name_id(trainfolder,filename,specie_name,recording_id,i,executor=executor))\n",
    "            except FileNotFoundError as e:\n",
    "                print(e)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "        complete_count = 0\n",
    "        print(df_in.species_id.unique())\n",
    "\n",
    "        for f in tqdm(asyncio.as_completed(filelist_coroutines), total=len(filelist_coroutines),mininterval=0.01,maxinterval=10, miniters=1):\n",
    "            result = await f\n",
    "            complete_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c316bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(\"species_index\", axis=1)\n",
    "y=df.species_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7032f39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split once to get the test and training set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=123, stratify=y)\n",
    "#Split twice to get the validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=123)\n",
    "print(X_train.shape, X_test.shape, X_val.shape, len(y_train), len(y_test), len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75d05c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use get_features to calculate and store the features\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=8,thread_name_prefix=\"birds\") as pool:\n",
    "    batch_size = 2500\n",
    "    # batch count\n",
    "    batch_count = len(X) // batch_size\n",
    "    print(f\"batch count: {batch_count}\")\n",
    "    for i in range(0, len(X), batch_size):\n",
    "        await get_features(pd.concat([X[i:i+batch_size], y[i:i+batch_size]], axis=1), \"all/\",pool)\n",
    "        print(f\"features {((i/batch_size)/batch_count)*100}% done\")\n",
    "        # await asyncio.sleep(1)\n",
    "\n",
    "    # print(\"mini_test done\")\n",
    "    # await get_features(pd.concat([X_train[:300], y_train[:300]], axis=1), \"mini_train/\",pool)\n",
    "    # print(\"mini_train done\")\n",
    "    # await get_features(pd.concat([X_test,y_test],axis=1), \"test/\",pool)\n",
    "    # print(\"test done\")\n",
    "    # await get_features(pd.concat([X_val,y_val],axis=1), \"val/\",pool)\n",
    "    # print(\"val done\")\n",
    "    # await get_features(pd.concat([X_train,y_train],axis=1), \"train/\",pool)\n",
    "    # print(\"train done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
