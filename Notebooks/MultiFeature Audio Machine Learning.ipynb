{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1517297",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-19 13:48:59.375946: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-19 13:49:00.733476: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TF_GPU_THREAD_MODE\"] = \"gpu_private\"\n",
    "\n",
    "import pandas as pd\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "# import librosa.display\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import normalize\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pickle\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import models, layers\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "\n",
    "import asyncio\n",
    "import concurrent.futures\n",
    "import functools\n",
    "\n",
    "# settings\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "tf.config.set_logical_device_configuration(physical_devices[0],[tf.config.LogicalDeviceConfiguration(memory_limit=3500)])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73695e0a",
   "metadata": {},
   "source": [
    "<h1>Audio ML with multiple features</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a0ac2b",
   "metadata": {},
   "source": [
    "<h2>Loading the Data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0e71c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "basePath = \"/home/birdo/MachineLearning/Data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61caeac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(basePath + \"bird_sounds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e382620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recording_id</th>\n",
       "      <th>species_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XC554370-ANAPLA_200229_5623_Fontbonne81_part_5...</td>\n",
       "      <td>Anas Platyrhynchos Linnaeus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XC605547-Wilde%20Eend%2020200621%202320%201a_p...</td>\n",
       "      <td>Anas Platyrhynchos Linnaeus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XC450266-20190105_165207%2B6%2C5sagcpato_part_...</td>\n",
       "      <td>Anas Platyrhynchos Linnaeus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XC618673-24_25_10_Anas_platyrrynchos_280_part_...</td>\n",
       "      <td>Anas Platyrhynchos Linnaeus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XC213601-magamo_fem_150215_sub_part_1.wav</td>\n",
       "      <td>Anas Platyrhynchos Linnaeus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89236</th>\n",
       "      <td>173192_part_0.wav</td>\n",
       "      <td>no bird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89237</th>\n",
       "      <td>39931_part_0.wav</td>\n",
       "      <td>no bird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89238</th>\n",
       "      <td>189268_part_0.wav</td>\n",
       "      <td>no bird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89239</th>\n",
       "      <td>146346_part_0.wav</td>\n",
       "      <td>no bird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89240</th>\n",
       "      <td>159171_part_0.wav</td>\n",
       "      <td>no bird</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89241 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            recording_id   \n",
       "0      XC554370-ANAPLA_200229_5623_Fontbonne81_part_5...  \\\n",
       "1      XC605547-Wilde%20Eend%2020200621%202320%201a_p...   \n",
       "2      XC450266-20190105_165207%2B6%2C5sagcpato_part_...   \n",
       "3      XC618673-24_25_10_Anas_platyrrynchos_280_part_...   \n",
       "4              XC213601-magamo_fem_150215_sub_part_1.wav   \n",
       "...                                                  ...   \n",
       "89236                                  173192_part_0.wav   \n",
       "89237                                   39931_part_0.wav   \n",
       "89238                                  189268_part_0.wav   \n",
       "89239                                  146346_part_0.wav   \n",
       "89240                                  159171_part_0.wav   \n",
       "\n",
       "                        species_id  \n",
       "0      Anas Platyrhynchos Linnaeus  \n",
       "1      Anas Platyrhynchos Linnaeus  \n",
       "2      Anas Platyrhynchos Linnaeus  \n",
       "3      Anas Platyrhynchos Linnaeus  \n",
       "4      Anas Platyrhynchos Linnaeus  \n",
       "...                            ...  \n",
       "89236                      no bird  \n",
       "89237                      no bird  \n",
       "89238                      no bird  \n",
       "89239                      no bird  \n",
       "89240                      no bird  \n",
       "\n",
       "[89241 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "315022c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Anas Platyrhynchos Linnaeus', 'Phylloscopus Collybita',\n",
       "       'Parus Major Linnaeus', 'Columba Palumbus Linnaeus',\n",
       "       'Passer Domesticus', 'Turdus Merula Linnaeus',\n",
       "       'Troglodytes Troglodytes', 'Phylloscopus Trochilus',\n",
       "       'Fringilla Coelebs Linnaeus', 'Sturnus Vulgaris Linnaeus',\n",
       "       'no bird'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.species_id.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d61846",
   "metadata": {},
   "source": [
    "## Train/val/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc837a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53544 17849 17848\n"
     ]
    }
   ],
   "source": [
    "allImPath = basePath + \"Images/all/\"\n",
    "allLabelPath = basePath + \"Labels/all/\"\n",
    "valid_files = []\n",
    "labels = []\n",
    "for img_file in os.listdir(allImPath):\n",
    "    if os.path.isfile(allImPath + img_file) and os.path.isfile(allLabelPath + img_file):\n",
    "        if os.path.isfile(allLabelPath + img_file):\n",
    "            valid_files.append(img_file)\n",
    "            f = open(allLabelPath + img_file, \"r\")\n",
    "            label = f.read()\n",
    "            f.close()\n",
    "            labels.append(label)\n",
    "        else:\n",
    "            print(\"No label could be found of: \" + img_file)\n",
    "    else:\n",
    "        continue \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    valid_files, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.25, random_state=42, stratify=y_train\n",
    ")  # 0.25 x 0.8 = 0.2\n",
    "print(len(y_train), len(y_test), len(y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9f2933",
   "metadata": {},
   "source": [
    "## Prepare data generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55184b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_DCT_OUTPUTS = 32\n",
    "MFCC_SIZE = 310\n",
    "CHANNELS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db31c1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sound_Generator(keras.utils.Sequence):\n",
    "    def __init__(self, image_filenames, labels, batch_size, directory):\n",
    "        self.image_filenames = image_filenames\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.imBasePath = basePath + str(\"Images/\") + directory\n",
    "        self.labelBasePath = basePath + str(\"Labels/\") + directory\n",
    "        self.executor = concurrent.futures.ThreadPoolExecutor(8)\n",
    "        random.seed(42)\n",
    "\n",
    "    def __get_all_labels__(self):\n",
    "        y = np.asarray(self.labels, dtype=np.float32)\n",
    "        return y\n",
    "\n",
    "    def __on_epoch_end(self):\n",
    "        c = list(zip(self.image_filenames, self.labels))\n",
    "        random.shuffle(c)\n",
    "        self.image_filenames, self.labels = zip(*c)\n",
    "\n",
    "    def __len__(self):\n",
    "        return (np.ceil(len(self.image_filenames) / float(self.batch_size))).astype(\n",
    "            np.int\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.image_filenames[\n",
    "            idx * self.batch_size : (idx + 1) * self.batch_size\n",
    "        ]\n",
    "        batch_y = self.labels[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
    "\n",
    "        X = self.get_images_data(batch_x, self.imBasePath)\n",
    "\n",
    "        X = np.asarray(X, dtype=np.float32)\n",
    "        y0 = np.asarray(batch_y, dtype=np.float32)\n",
    "\n",
    "        return X, y0\n",
    "\n",
    "    def get_image_data(self,file_path):\n",
    "        _data = np.fromfile(file_path, dtype=np.float64)\n",
    "        return _data.reshape((MFCC_SIZE, NUM_DCT_OUTPUTS, CHANNELS))\n",
    "\n",
    "    def get_images_data(self,_batch_x, _imBasePath):\n",
    "        tasks = [\n",
    "            self.executor.submit(self.get_image_data,_imBasePath + _image_f)\n",
    "            for _image_f in _batch_x\n",
    "        ]\n",
    "        return [task.result() for task in tasks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6771fd6a",
   "metadata": {},
   "source": [
    "## Load an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6df2b62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turdus Merula Linnaeus-XC353083-1402_000-02tut%20mp3_part_7.npy\n",
      "(310, 32, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4b5698aa00>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_test_test = X_test[15000]\n",
    "print(X_test_test)\n",
    "image = np.fromfile((allImPath + X_test_test), dtype=np.float64).reshape(\n",
    "    (MFCC_SIZE,NUM_DCT_OUTPUTS, CHANNELS)\n",
    ")\n",
    "print(image.shape)\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbbf3fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "train_batch_generator = Sound_Generator(X_train, y_train, batch_size, \"all/\")\n",
    "val_batch_generator = Sound_Generator(X_val, y_val, batch_size, \"all/\")\n",
    "test_batch_generator = Sound_Generator(X_test, y_test, batch_size, \"all/\")\n",
    "mini_train_batch_generator = Sound_Generator(\n",
    "    X_train[:400], y_train[:400], batch_size, \"all/\"\n",
    ")\n",
    "mini_test_batch_generator = Sound_Generator(\n",
    "    X_val[:100], y_val[:100], batch_size, \"all/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8821463",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be1649ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-19 11:49:54.920449: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:226] Using CUDA malloc Async allocator for GPU: 0\n",
      "2023-06-19 11:49:54.920824: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3500 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:00:10.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_tanh (Conv2D)        (None, 310, 32, 8)        400       \n",
      "                                                                 \n",
      " maxpool2d_1 (MaxPooling2D)  (None, 155, 16, 8)        0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 155, 16, 8)        0         \n",
      "                                                                 \n",
      " conv2d_relu_1 (Conv2D)      (None, 155, 16, 16)       3216      \n",
      "                                                                 \n",
      " maxpool2d_2 (MaxPooling2D)  (None, 77, 8, 16)         0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 77, 8, 16)         0         \n",
      "                                                                 \n",
      " conv2d_relu_2 (Conv2D)      (None, 77, 8, 16)         2320      \n",
      "                                                                 \n",
      " max_pool_2d_3 (MaxPooling2D  (None, 39, 4, 16)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 39, 4, 16)         0         \n",
      "                                                                 \n",
      " conv2d_relu_3 (Conv2D)      (None, 39, 4, 32)         4640      \n",
      "                                                                 \n",
      " max_pool_2d_4 (MaxPooling2D  (None, 20, 2, 32)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 20, 2, 32)         0         \n",
      "                                                                 \n",
      " conv2d_relu_4 (Conv2D)      (None, 20, 2, 32)         9248      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1280)              0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1280)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                81984     \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " softmax (Dense)             (None, 11)                363       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 104,251\n",
      "Trainable params: 104,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (MFCC_SIZE, NUM_DCT_OUTPUTS, CHANNELS)\n",
    "n_classes = df.species_id.unique().shape[0]\n",
    "CNNmodel = models.Sequential()\n",
    "\n",
    "CNNmodel.add(layers.Conv2D(8, kernel_size=(7,7),input_shape=input_shape, activation='tanh', padding='same', name='conv2d_tanh', kernel_regularizer=l2(0.001)))\n",
    "CNNmodel.add(layers.MaxPooling2D(pool_size=(2,2), name='maxpool2d_1'))\n",
    "CNNmodel.add(layers.Dropout(rate=0.2, name='dropout_1'))\n",
    "\n",
    "CNNmodel.add(layers.Conv2D(16, kernel_size=(5,5), activation='relu', padding='same', name='conv2d_relu_1',kernel_regularizer=l2(0.001)))\n",
    "CNNmodel.add(layers.MaxPooling2D(pool_size=(2,2), name='maxpool2d_2'))\n",
    "CNNmodel.add(layers.Dropout(rate=0.2, name='dropout_2'))\n",
    "\n",
    "CNNmodel.add(layers.Conv2D(16, kernel_size=(3,3), activation='relu', padding='same', name='conv2d_relu_2',kernel_regularizer=l2(0.001)))\n",
    "CNNmodel.add(layers.MaxPooling2D(pool_size=(2,2), padding='same', name='max_pool_2d_3'))\n",
    "CNNmodel.add(layers.Dropout(rate=0.2, name='dropout_3'))\n",
    "\n",
    "CNNmodel.add(layers.Conv2D(32, kernel_size=(3,3), activation='relu', padding='same', name='conv2d_relu_3',kernel_regularizer=l2(0.001)))\n",
    "CNNmodel.add(layers.MaxPooling2D(pool_size=(2,2), padding='same', name='max_pool_2d_4'))\n",
    "CNNmodel.add(layers.Dropout(rate=0.2, name='dropout_4'))\n",
    "\n",
    "CNNmodel.add(layers.Conv2D(32, kernel_size=(3,3), activation='relu', padding='same', name='conv2d_relu_4', kernel_regularizer=l2(0.001)))\n",
    "CNNmodel.add(layers.Flatten(name='flatten'))\n",
    "CNNmodel.add(layers.Dropout(rate=0.2, name='dropout_5'))\n",
    "\n",
    "CNNmodel.add(layers.Dense(64, activation='relu', activity_regularizer=l2(0.001),kernel_regularizer=l2(0.001), name='dense'))\n",
    "CNNmodel.add(layers.Dropout(rate=0.2, name='dropout_6'))\n",
    "CNNmodel.add(layers.Dense(32, activation=\"relu\", name='dense_2'))\n",
    "CNNmodel.add(layers.Dense(n_classes, activation='softmax', name='softmax'))\n",
    "CNNmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9440f35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = True\n",
    "if load_model:\n",
    "    CNNmodel = tf.keras.models.load_model(basePath + str(\"/Models/MFCCOnly\"))\n",
    "else:\n",
    "    CNNmodel.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "        metrics=[\"accuracy\"],\n",
    "        jit_compile=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b406fc4",
   "metadata": {},
   "source": [
    "## Define tensorflow callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffda9751",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-19 11:49:56.312753: I tensorflow/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2023-06-19 11:49:56.312786: I tensorflow/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2023-06-19 11:49:56.317948: I tensorflow/compiler/xla/backends/profiler/gpu/cupti_tracer.cc:1679] Profiler found 1 GPUs\n",
      "2023-06-19 11:49:56.350257: I tensorflow/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2023-06-19 11:49:56.350444: I tensorflow/compiler/xla/backends/profiler/gpu/cupti_tracer.cc:1813] CUPTI activity buffer flushed\n"
     ]
    }
   ],
   "source": [
    "log_dir = basePath + \"logs/MFCCOnly/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1,profile_batch='10, 15')\n",
    "file_writer_cm = tf.summary.create_file_writer(log_dir + \"/cm\")\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=basePath + str(\"/Models/MFCCOnly\"),\n",
    "    save_weights_only=False,\n",
    "    monitor=\"val_accuracy\",\n",
    "    save_best_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c230b5be",
   "metadata": {},
   "source": [
    "### Define Confusion Matrix callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c7b4635",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, class_names):\n",
    "    \"\"\"\n",
    "    Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "\n",
    "    Args:\n",
    "       cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
    "       class_names (array, shape = [n]): String names of the integer classes\n",
    "    \"\"\"\n",
    "\n",
    "    figure = plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "\n",
    "    # Normalize the confusion matrix.\n",
    "    # cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "    # Use white text if squares are dark; otherwise black.\n",
    "    threshold = cm.max() / 2.0\n",
    "\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        color = \"white\" if cm[i, j] > threshold else \"black\"\n",
    "        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    return figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55497983",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_to_image(figure):\n",
    "    \"\"\"\n",
    "    Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "    returns it. The supplied figure is closed and inaccessible after this call.\n",
    "    \"\"\"\n",
    "\n",
    "    buf = io.BytesIO()\n",
    "\n",
    "    # Use plt.savefig to save the plot to a PNG in memory.\n",
    "    plt.savefig(buf, format=\"png\")\n",
    "\n",
    "    # Closing the figure prevents it from being displayed directly inside\n",
    "    # the notebook.\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "\n",
    "    # Use tf.image.decode_png to convert the PNG buffer\n",
    "    # to a TF image. Make sure you use 4 channels.\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "\n",
    "    # Use tf.expand_dims to add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7cb09a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_confusion_matrix(epoch, logs):\n",
    "    batch_generator = val_batch_generator\n",
    "\n",
    "    figure = generate_cm(batch_generator)\n",
    "    cm_image = plot_to_image(figure)\n",
    "\n",
    "    # Log the confusion matrix as an image summary.\n",
    "    with file_writer_cm.as_default():\n",
    "        tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdf8f2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cm(generator):\n",
    "    y_pred_raw = CNNmodel.predict(generator)\n",
    "    y_pred = np.argmax(y_pred_raw, axis=1)\n",
    "    y_true = generator.__get_all_labels__()\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    figure = plot_confusion_matrix(cm, class_names=df.species_id.unique())\n",
    "    return figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e35c6327",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_callback = keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c7a7ca",
   "metadata": {},
   "source": [
    "## Calculate class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9846d17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 2.5787724672022194, 1: 1.2972206878506847, 2: 0.9040359016958082, 3: 2.0909325210871605, 4: 1.3541676150589521, 5: 0.5250335349351658, 6: 1.1275633331227495, 7: 0.3889547503029141, 8: 1.5746929700734047, 9: 1.2322020324754224, 10: 1.4096990759023773}\n"
     ]
    }
   ],
   "source": [
    "weights = []\n",
    "for specie in df.species_id.unique():\n",
    "    amount = len(df[df[\"species_id\"] == specie])\n",
    "    weight = (1 / amount) * (len(df) / len(df.species_id.unique()))\n",
    "    weights.append(weight)\n",
    "zip_weights = zip(range(0, len(df.species_id.unique())), weights)\n",
    "class_weights = {}\n",
    "for (\n",
    "    i,\n",
    "    w,\n",
    ") in zip_weights:\n",
    "    class_weights[i] = w\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe3d090",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e7c9d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-19 11:49:57.123863: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-19 11:49:58.700383: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_11/dropout_1/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2023-06-19 11:49:59.118191: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8901\n",
      "2023-06-19 11:50:00.274815: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f4ae40240e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-06-19 11:50:00.274857: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce GTX 1650, Compute Capability 7.5\n",
      "2023-06-19 11:50:00.322962: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-06-19 11:50:00.683707: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12/536 [..............................] - ETA: 21s - loss: 0.7408 - accuracy: 0.8433"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-19 11:50:04.194168: I tensorflow/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2023-06-19 11:50:04.194215: I tensorflow/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 14/536 [..............................] - ETA: 20s - loss: 0.7384 - accuracy: 0.8421"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-19 11:50:04.479477: I tensorflow/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n",
      "2023-06-19 11:50:04.483728: I tensorflow/compiler/xla/backends/profiler/gpu/cupti_tracer.cc:1813] CUPTI activity buffer flushed\n",
      "2023-06-19 11:50:04.497882: I tensorflow/compiler/xla/backends/profiler/gpu/cupti_collector.cc:541]  GpuTracer has collected 1803 callback api events and 1798 activity events. \n",
      "2023-06-19 11:50:04.513829: I tensorflow/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536/536 [==============================] - ETA: 0s - loss: 0.7783 - accuracy: 0.8065"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-19 11:50:43.219757: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-19 11:51:03.969299: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,155,16,8]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-19 11:51:03.989030: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,77,8,16]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-19 11:51:04.008259: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,39,4,16]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-19 11:51:04.026924: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,20,2,32]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-19 11:51:04.052234: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1280]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-19 11:51:04.079303: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,64]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-19 11:51:04.674388: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,155,16,8]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-19 11:51:04.731505: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,77,8,16]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-19 11:51:04.784280: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,39,4,16]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-19 11:51:04.838139: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,20,2,32]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-19 11:51:04.897100: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1280]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-19 11:51:04.964000: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,64]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/birdo/MachineLearning/Data//Models/MFCCOnly/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/birdo/MachineLearning/Data//Models/MFCCOnly/assets\n",
      "2023-06-19 11:51:06.957013: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179/179 [==============================] - 6s 30ms/step\n",
      "536/536 [==============================] - 77s 131ms/step - loss: 0.7783 - accuracy: 0.8065 - val_loss: 0.6736 - val_accuracy: 0.8340\n",
      "Epoch 2/32\n",
      "  3/179 [..............................] - ETA: 6s - loss: 0.7758 - accuracy: 0.810"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-19 11:52:12.804666: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179/179 [==============================] - 6s 30ms/step\n",
      "536/536 [==============================] - 65s 122ms/step - loss: 0.7758 - accuracy: 0.8100 - val_loss: 0.7011 - val_accuracy: 0.8268\n",
      "Epoch 3/32\n",
      "  5/179 [..............................] - ETA: 5s - loss: 0.7714 - accuracy: 0.8"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-19 11:53:16.498952: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179/179 [==============================] - 6s 31ms/step\n",
      "536/536 [==============================] - 64s 119ms/step - loss: 0.7714 - accuracy: 0.8085 - val_loss: 0.6851 - val_accuracy: 0.8302\n",
      "Epoch 4/32\n",
      "  3/179 [..............................] - ETA: 11s- loss: 0.7688 - accuracy: 0.80"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-19 11:54:20.777472: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179/179 [==============================] - 5s 30ms/step\n",
      "536/536 [==============================] - 64s 120ms/step - loss: 0.7688 - accuracy: 0.8097 - val_loss: 0.6981 - val_accuracy: 0.8259\n",
      "Epoch 5/32\n",
      "163/536 [========>.....................] - ETA: 22s - loss: 0.7666 - accuracy: 0.8081"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m train_gen \u001b[39m=\u001b[39m train_batch_generator\n\u001b[1;32m      2\u001b[0m val_gen \u001b[39m=\u001b[39m val_batch_generator\n\u001b[0;32m----> 4\u001b[0m CNNmodel\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m      5\u001b[0m     train_gen,\n\u001b[1;32m      6\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m,\n\u001b[1;32m      7\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m      8\u001b[0m     validation_data\u001b[39m=\u001b[39;49mval_gen,\n\u001b[1;32m      9\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[tensorboard_callback, model_checkpoint_callback, cm_callback],\n\u001b[1;32m     10\u001b[0m     class_weight\u001b[39m=\u001b[39;49mclass_weights,\n\u001b[1;32m     11\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/birds/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/birds/lib/python3.9/site-packages/keras/engine/training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m ):\n\u001b[1;32m   1684\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1685\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1686\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1687\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/birds/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/birds/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/birds/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    923\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    924\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    925\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    929\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    930\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/birds/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/birds/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/birds/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    382\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    383\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    384\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    385\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    386\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    387\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniconda3/envs/birds/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_gen = train_batch_generator\n",
    "val_gen = val_batch_generator\n",
    "\n",
    "CNNmodel.fit(\n",
    "    train_gen,\n",
    "    epochs=32,\n",
    "    verbose=1,\n",
    "    validation_data=val_gen,\n",
    "    callbacks=[tensorboard_callback, model_checkpoint_callback, cm_callback],\n",
    "    class_weight=class_weights,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35a8be8",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2541822e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = generate_cm(test_batch_generator)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ac7727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the model.\n",
    "\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(CNNmodel)\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "converter.inference_input_type = tf.float32\n",
    "converter.inference_output_type = tf.float32\n",
    "converter.optimizations = {tf.lite.Optimize.DEFAULT}\n",
    "# set too support only float32 input and output\n",
    "converter.target_spec.supported_types = [tf.float32]\n",
    "\n",
    "\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "# print size of model\n",
    "print(\"Size of model: \", len(tflite_model) / 1024, \" kb\")\n",
    "\n",
    "with open(basePath+'model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
